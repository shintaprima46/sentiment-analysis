{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setelah data diambil dari twitter dalam bentuk html, sekarang kita akan mengubah html tsb ke bentuk csv, html tiap bulan jadi csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "189it [00:02, 82.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Data to \"C:/WinPython_64bit/notebooks/analisis gopay/gopay OR go-pay since 2018-10-01 until 2018-10-31 - Twitter Search.csv\" \n",
      "All Finished\n"
     ]
    }
   ],
   "source": [
    "#bulan Oktober\n",
    "fileSource = 'C:/WinPython_64bit/notebooks/analisis gopay/gopay OR go-pay since 2018-10-01 until 2018-10-31 - Twitter Search.html'\n",
    "fileOutput = 'C:/WinPython_64bit/notebooks/analisis gopay/gopay OR go-pay since 2018-10-01 until 2018-10-31 - Twitter Search.csv'\n",
    "\n",
    "TS.twitter_html2csv(fileSource, fileOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "208it [00:02, 83.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Data to \"C:/WinPython_64bit/notebooks/analisis gopay/gopay OR go-pay since 2018-11-01 until 2018-11-30 - Twitter Search.csv\" \n",
      "All Finished\n"
     ]
    }
   ],
   "source": [
    "#bulan November\n",
    "fileSource = 'C:/WinPython_64bit/notebooks/analisis gopay/gopay OR go-pay since 2018-11-01 until 2018-11-30 - Twitter Search.html'\n",
    "fileOutput = 'C:/WinPython_64bit/notebooks/analisis gopay/gopay OR go-pay since 2018-11-01 until 2018-11-30 - Twitter Search.csv'\n",
    "\n",
    "TS.twitter_html2csv(fileSource, fileOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "280it [00:03, 83.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Data to \"C:/WinPython_64bit/notebooks/analisis gopay/gopay OR go-pay since 2018-12-01 until 2018-12-31 - Twitter Search.csv\" \n",
      "All Finished\n"
     ]
    }
   ],
   "source": [
    "#bulan Desember\n",
    "fileSource = 'C:/WinPython_64bit/notebooks/analisis gopay/gopay OR go-pay since 2018-12-01 until 2018-12-31 - Twitter Search.html'\n",
    "fileOutput = 'C:/WinPython_64bit/notebooks/analisis gopay/gopay OR go-pay since 2018-12-01 until 2018-12-31 - Twitter Search.csv'\n",
    "\n",
    "TS.twitter_html2csv(fileSource, fileOutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### semua csv digabung jadi 1 csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gabungin semua csv\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas\n",
    "\n",
    "def concatenate(indir='C:/WinPython_64bit/notebooks/analisis gopay/perbulan/',outfile='C:/WinPython_64bit/notebooks/analisis gopay/perbulan/gabungan.csv'):\n",
    "    os.chdir(indir)\n",
    "    fileList=glob.glob(\"*.csv\")\n",
    "    dfList=[]\n",
    "    colnames=[\"Time\",\"Username\",\"Tweet\",\"Replies\",\"Retweets\",\"Likes\",\"Language\",\"urlStatus\"]\n",
    "    for filename in fileList:\n",
    "        print(filename)\n",
    "        df=pandas.read_csv(filename,header=None)\n",
    "        dfList.append(df)\n",
    "    concatDF=pandas.concat(dfList,axis=0)\n",
    "    concatDF.columns=colnames\n",
    "    concatDF.to_csv(outfile,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gopay OR go-pay since 2018-10-01 until 2018-10-31 - Twitter Search.csv\n",
      "gopay OR go-pay since 2018-11-01 until 2018-11-30 - Twitter Search.csv\n",
      "gopay OR go-pay since 2018-12-01 until 2018-12-31 - Twitter Search.csv\n"
     ]
    }
   ],
   "source": [
    "concatenate() #ini isi csv-nya ada apa aja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#membuat csv menjadi list\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('gabungan.csv')\n",
    "Data = []\n",
    "for i in range(len(data)):\n",
    "    Data.append(data[' Tweet'][i])\n",
    "len(Data) #panjang data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Language</th>\n",
       "      <th>urlStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30-Oct-18</td>\n",
       "      <td>@gagalselingkuh</td>\n",
       "      <td>bismillah...\\r\\n\\r\\nmau giveaway Rp 50.000 dal...</td>\n",
       "      <td>613</td>\n",
       "      <td>1037</td>\n",
       "      <td>222</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>https://twitter.com/gagalselingkuh/status/1057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30-Oct-18</td>\n",
       "      <td>@askmenfess</td>\n",
       "      <td>[askmf] siapa yg mau saldo gopay? https://twit...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>https://twitter.com/askmenfess/status/10572635...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30-Oct-18</td>\n",
       "      <td>@muoonlight</td>\n",
       "      <td>GA gopay &amp; pulsa all operator masing2 10k. \\r\\...</td>\n",
       "      <td>40</td>\n",
       "      <td>541</td>\n",
       "      <td>50</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>https://twitter.com/muoonlight/status/10572458...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30-Oct-18</td>\n",
       "      <td>@AsikinHidup</td>\n",
       "      <td>Sambil nungguin gue topup gopay, gimana kalo g...</td>\n",
       "      <td>43</td>\n",
       "      <td>23</td>\n",
       "      <td>85</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>https://twitter.com/AsikinHidup/status/1057234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30-Oct-18</td>\n",
       "      <td>@dreamyoonjh</td>\n",
       "      <td>[GIVEAWAY]\\r\\nKarena hari ini aku ultah dan di...</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>https://twitter.com/dreamyoonjh/status/1057212...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time         Username  \\\n",
       "0  30-Oct-18  @gagalselingkuh   \n",
       "1  30-Oct-18      @askmenfess   \n",
       "2  30-Oct-18      @muoonlight   \n",
       "3  30-Oct-18     @AsikinHidup   \n",
       "4  30-Oct-18     @dreamyoonjh   \n",
       "\n",
       "                                               Tweet   Replies   Retweets  \\\n",
       "0  bismillah...\\r\\n\\r\\nmau giveaway Rp 50.000 dal...       613       1037   \n",
       "1  [askmf] siapa yg mau saldo gopay? https://twit...         7          2   \n",
       "2  GA gopay & pulsa all operator masing2 10k. \\r\\...        40        541   \n",
       "3  Sambil nungguin gue topup gopay, gimana kalo g...        43         23   \n",
       "4  [GIVEAWAY]\\r\\nKarena hari ini aku ultah dan di...        22         52   \n",
       "\n",
       "    Likes    Language                                          urlStatus  \n",
       "0     222  Indonesian  https://twitter.com/gagalselingkuh/status/1057...  \n",
       "1       1  Indonesian  https://twitter.com/askmenfess/status/10572635...  \n",
       "2      50  Indonesian  https://twitter.com/muoonlight/status/10572458...  \n",
       "3      85  Indonesian  https://twitter.com/AsikinHidup/status/1057234...  \n",
       "4      43  Indonesian  https://twitter.com/dreamyoonjh/status/1057212...  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() #diliatin beberapa data awal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mulai preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading StopWords & Slang ... \n",
      "Loading Data: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:21<00:00,  7.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Data to \"gabungan_bersih.csv\" \n",
      "All Finished\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import re,csv, os, itertools\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from spacy.lang.id import Indonesian\n",
    "from html import unescape\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "fData = 'gabungan.csv'\n",
    "fName=\"gabungan_bersih.csv\"\n",
    "fSlang = 'C:/WinPython_64bit/notebooks/analisis gopay/perbulan/slang.dic'\n",
    "dPath = 'C:/WinPython_64bit/notebooks/analisis gopay/perbulan/'\n",
    "bahasa = 'id'\n",
    "\n",
    "#ngilangin stopword\n",
    "\n",
    "def LoadStopWords(lang):\n",
    "    L = lang.lower().strip()\n",
    "    if L == 'en' or L == 'english' or L == 'inggris':\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        stops =  set([t.strip() for t in LoadDocuments(file = 'C:/WinPython_64bit/notebooks/analisis gopay/perbulan/stopwords_eng.txt')[0]])\n",
    "    elif L == 'id' or L == 'indonesia' or L=='indonesian':\n",
    "        lemmatizer = Indonesian() \n",
    "        stops = set([t.strip() for t in LoadDocuments(file = 'C:/WinPython_64bit/notebooks/analisis gopay/perbulan/stopwords_id.txt')[0]])\n",
    "    else:\n",
    "        print('Warning, language not recognized. Empty StopWords Given')\n",
    "        stops = set(); lemmatizer = None\n",
    "    return stops, lemmatizer\n",
    "\n",
    "# HashTags Processing belum ada\n",
    "def crawlFiles(dPath,types=None): # dPath ='C:/Temp/', types = 'pdf'\n",
    "    if types:\n",
    "        return [dPath+'/'+f for f in os.listdir(dPath) if f.endswith('.'+types)]\n",
    "    else:\n",
    "        return [dPath+'/'+f for f in os.listdir(dPath)]\n",
    "    \n",
    "def fixTags(T):\n",
    "    getHashtags = re.compile(r\"#(\\w+)\")\n",
    "    pisahtags = re.compile(r'[A-Z][^A-Z]*')\n",
    "    t = T\n",
    "    tagS = re.findall(getHashtags, T)\n",
    "    for tag in tagS:\n",
    "        proper_words = ' '.join(re.findall(pisahtags, tag))\n",
    "        t = t.replace('#'+tag,proper_words)\n",
    "    return t\n",
    "\n",
    "def LoadDocuments(dPath=None,types=None, file = None): # types = ['pdf','doc','docx','txt','bz2']\n",
    "    Files, Docs = [], []\n",
    "    if types:\n",
    "        for tipe in types:\n",
    "            Files += crawlFiles(dPath,tipe)\n",
    "    if file:\n",
    "        Files = [file]\n",
    "    if not types and not file: # get all files regardless of their extensions\n",
    "        Files += crawlFiles(dPath)\n",
    "    for f in Files:\n",
    "        if f[-3:].lower()=='txt':\n",
    "            try:\n",
    "                df=open(f,\"r\",encoding=\"utf-8\", errors='replace')\n",
    "                Docs.append(df.readlines());df.close()\n",
    "            except:\n",
    "                print('error reading{0}'.format(f))\n",
    "        else:\n",
    "            print('Unsupported format {0}'.format(f))\n",
    "    if file:\n",
    "        Docs = Docs[0]\n",
    "    return Docs, Files\n",
    "\n",
    "# filtering\n",
    "\n",
    "# T sembarang string (e.g. kalimat)\n",
    "def cleanText(T, fix={}, lang = 'en', lemmatizer=None, stops = set(), symbols_remove = False, min_charLen = 0): \n",
    "    # lang & stopS only 2 options : 'en' atau 'id'\n",
    "    # symbols ASCII atau alnum\n",
    "    pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    t = re.sub(pattern,' ',T) #remove urls if any\n",
    "    t = unescape(t) # html entities fix\n",
    "    t = fixTags(t) # fix abcDef\n",
    "    t = t.lower().strip() # lowercase\n",
    "    t = unidecode(t)\n",
    "    t = ''.join(''.join(s)[:2] for _, s in itertools.groupby(t)) # remove repetition\n",
    "    t = sent_tokenize(t) # sentence segmentation. String to list\n",
    "    for i, K in enumerate(t):\n",
    "        if symbols_remove:\n",
    "            K = re.sub(r'[^.,a-zA-Z0-9 \\n\\.]',' ',K)\n",
    "        \n",
    "        cleanList = []\n",
    "        if lang =='en':\n",
    "            listKata = word_tokenize(K) # word tokenize\n",
    "            for token in listKata:\n",
    "                if token in fix.keys():\n",
    "                    token = fix[token]\n",
    "                if lemmatizer:\n",
    "                    token = lemmatizer.lemmatize(token)\n",
    "                if stops:\n",
    "                    if len(token)>=min_charLen and token not in stops:\n",
    "                        cleanList.append(token)\n",
    "                else:\n",
    "                    if len(token)>=min_charLen:\n",
    "                        cleanList.append(token)\n",
    "            t[i] = ' '.join(cleanList)\n",
    "        else:\n",
    "            K = lemmatizer(K)\n",
    "            listKata = [token.text for token in K]\n",
    "            for token in listKata:\n",
    "                if token in fix.keys():\n",
    "                    token = fix[token]\n",
    "                \n",
    "                if lemmatizer:\n",
    "                    token = lemmatizer(token)[0].lemma_\n",
    "                if stops:    \n",
    "                    if len(token)>=min_charLen and token not in stops:\n",
    "                        cleanList.append(token)\n",
    "                else:\n",
    "                    if len(token)>=min_charLen:\n",
    "                        cleanList.append(token)\n",
    "            t[i] = ' '.join(cleanList)\n",
    "    return ' '.join(t) # Return kalimat lagi\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print('Loading StopWords & Slang ... ', flush = True)\n",
    "    stops, lemmatizer = LoadStopWords(bahasa)\n",
    "    sw=open(fSlang,encoding='utf-8', errors ='ignore', mode='r');SlangS=sw.readlines();sw.close()\n",
    "    SlangS = {slang.strip().split(':')[0]:slang.strip().split(':')[1] for slang in SlangS}\n",
    "    # Dictionary comprehension, bentuk umum:\n",
    "    # D = {k:v for v in List}\n",
    "    tokenizer=RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    print('Loading Data: ', flush = True)\n",
    "    allData = crawlFiles(dPath, types='html')\n",
    "    Tweets, Clean_Tweets, Username, waktu, replies, retweets, likes, Language = [], [], [], [], [], [], [], []\n",
    "    # fData = allData[0]\n",
    "    for fData in tqdm(allData):\n",
    "        soup = bs(open(fData,encoding='utf-8', errors = 'ignore', mode='r'),'html.parser')\n",
    "        data = soup.find_all('li', class_= 'stream-item')\n",
    "        # t = data[0]\n",
    "        for t in data:\n",
    "            try:\n",
    "                # Loading tweet\n",
    "                T = t.find_all('p',class_='TweetTextSize')[0]\n",
    "                T = bs(str(T),'html.parser').text\n",
    "                Tweets.append(T)\n",
    "                T = cleanText(T, fix=SlangS, lang = bahasa, lemmatizer=lemmatizer, stops = stops, symbols_remove = True, min_charLen = 2)\n",
    "                Clean_Tweets.append(T)\n",
    "                # Loading UserName\n",
    "                U = t.find_all('span',class_='username')\n",
    "                U = bs(str(U[0]),'html.parser').text\n",
    "                Username.append(U)\n",
    "                # Loading Time\n",
    "                T = t.find_all('a',class_='tweet-timestamp')[0]\n",
    "                T = bs(str(T),'html.parser').text\n",
    "                waktu.append(T)\n",
    "                # Loading reply, retweet & Likes\n",
    "                RP = t.find_all('span',class_='ProfileTweet-actionCountForAria')[0]\n",
    "                RT = t.find_all('span',class_='ProfileTweet-actionCountForAria')[1]\n",
    "                L  = t.find_all('span',class_='ProfileTweet-actionCountForAria')[2] \n",
    "                RP = int(bs(str(RP), \"lxml\").text.split()[0])\n",
    "                RT = int(bs(str(RT), \"lxml\").text.split()[0])\n",
    "                L = int(bs(str(L), \"lxml\").text.split()[0])\n",
    "                replies.append(RP)\n",
    "                retweets.append(RT)\n",
    "                likes.append(L)\n",
    "                # Loading Bahasa\n",
    "                try:\n",
    "                    L = t.find_all('span',class_='tweet-language')\n",
    "                    L = bs(str(L[0]), \"lxml\").text\n",
    "                except:\n",
    "                    L =''\n",
    "                Language.append(L)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    print('Saving Data to \"%s\" ' %fName, flush = True)\n",
    "    N = len (Tweets)\n",
    "    dfile = open(fName, 'w', encoding='utf-8', newline='')\n",
    "    dfile.write('Username,Time,Tweet,Cleaned_Tweet\\n')\n",
    "    # Tweets, Clean_Tweets, Username, waktu, replies, retweets, likes, Language\n",
    "    with dfile :\n",
    "        writer = csv.writer(dfile)\n",
    "        for i in range(N):\n",
    "            writer.writerow([Username[i],waktu[i],Tweets[i],Clean_Tweets[i]])\n",
    "    dfile.close()\n",
    "             \n",
    "    print('All Finished', flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fData = 'gabungan.csv'\n",
    "fName=\"gabungan_bersih.csv\"\n",
    "fSlang = 'C:/WinPython_64bit/notebooks/analisis gopay/slang.dic'\n",
    "dPath = 'C:/WinPython_64bit/notebooks/analisis gopay/perbulan'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweet belum dibersihkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    bismillah...\\r\\n\\r\\nmau giveaway Rp 50.000 dal...\n",
       "1    [askmf] siapa yg mau saldo gopay? https://twit...\n",
       "2    GA gopay & pulsa all operator masing2 10k. \\r\\...\n",
       "3    Sambil nungguin gue topup gopay, gimana kalo g...\n",
       "4    [GIVEAWAY]\\r\\nKarena hari ini aku ultah dan di...\n",
       "Name:  Tweet, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('C:/WinPython_64bit/notebooks/analisis gopay/perbulan/gabungan.csv')\n",
    "data.head()\n",
    "Data = data[' Tweet']\n",
    "Data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweet sudah dibersihkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    bismillah .. \\n\\n rp 50.00 bentuk    pulsa beb...\n",
       "1                                       askmf saldo ..\n",
       "2       pulsa all operator masing2 10k rulesnya rt ...\n",
       "3               nungguin gue topup gimana terakir hari\n",
       "4    hari ultah diumumkan superstar pledis saldo pa...\n",
       "Name: Cleaned_Tweet, dtype: object"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('C:/WinPython_64bit/notebooks/analisis gopay/perbulan/gabungan_bersih.csv')\n",
    "df.head()\n",
    "Tweets = df['Cleaned_Tweet']\n",
    "Tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os  \n",
    "os.path.isfile('C:/WinPython_64bit/notebooks/analisis gopay/perbulan/gabungan_bersih _labeled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ini kalo coba diliatin hasil2 dari masing2 tahap preprocessing, namun komputasinya mungkin lama, maka biasanya preprocessing itu prosesnya langsung semua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nah! Di app GO-JEK sekarang, kita bisa #KasihLebih juga pake GO-PAY! Bentuk apresiasi buat orang yang mageran kaya gue. Dibantu kirim2 barang, dan gue bisa berterima kasih dalam bentuk nyata. https://twitter.com/gojekindonesia/status/1053518908777410560 …\n"
     ]
    }
   ],
   "source": [
    "print(Data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nah! Di app GO-JEK sekarang, kita bisa #KasihLebih juga pake GO-PAY! Bentuk apresiasi buat orang yang mageran kaya gue. Dibantu kirim2 barang, dan gue bisa berterima kasih dalam bentuk nyata.   …\n"
     ]
    }
   ],
   "source": [
    "#menghilangkan url\n",
    "import re\n",
    "urlPattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "\n",
    "#txt = 'website reguler expression & my site : https://www.regular-expressions.info/ & http://taufiksutanto.blogspot.com'\n",
    "filter=re.sub(urlPattern,' ',Data[10])\n",
    "print(filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nah  Di app GO JEK sekarang  kita bisa  KasihLebih juga pake GO PAY  Bentuk apresiasi buat orang yang mageran kaya gue  Dibantu kirim2 barang  dan gue bisa berterima kasih dalam bentuk nyata     \n"
     ]
    }
   ],
   "source": [
    "# filtering simbol\n",
    "\n",
    "import re\n",
    "filtering=re.sub(r'[^\\w]',' ',filter)\n",
    "print(filtering)\n",
    "# atau jika ingin exclude titik dan koma \n",
    "# re.sub(r'[^.,a-zA-Z0-9 \\n\\.]','',txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nah  di app go jek sekarang  kita bisa  kasihlebih juga pake go pay  bentuk apresiasi buat orang yang mageran kaya gue  dibantu kirim2 barang  dan gue bisa berterima kasih dalam bentuk nyata     \n"
     ]
    }
   ],
   "source": [
    "# case folding = nyamain semua huruf jadi kecil\n",
    "\n",
    "casefolding=filtering.lower() #save hasil case folding dgn varibel baru, utk nanti dipanggil di langkah selanjutnya\n",
    "print(casefolding) # x[10] -> variabel x di baris ke-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error readingdata/stopwords_eng.txt\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-05fde86e12c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mNLTK_StopWords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mastrawi_StopWords_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfactory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_stop_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mPersonal_StopWords_en\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mittc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLoadDocuments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data/stopwords_eng.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mPersonal_StopWords_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mittc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLoadDocuments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data/stopwords_id.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mSastrawi_StopWords_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfactory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_stop_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WinPython_64bit\\notebooks\\analisis gopay\\TSutanto_lib.py\u001b[0m in \u001b[0;36mLoadDocuments\u001b[1;34m(dPath, types, file)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unsupported format {0}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m         \u001b[0mDocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mDocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#hapus stopword\n",
    "\n",
    "import TSutanto_lib as ittc\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "factory = StopWordRemoverFactory()\n",
    "NLTK_StopWords = stopwords.words('english')\n",
    "astrawi_StopWords_id = factory.get_stop_words()\n",
    "Personal_StopWords_en = [t.strip() for t in ittc.LoadDocuments(file = 'data/stopwords_eng.txt')[0]]\n",
    "Personal_StopWords_id = [t.strip() for t in ittc.LoadDocuments(file = 'data/stopwords_id.txt')[0]]\n",
    "Sastrawi_StopWords_id = factory.get_stop_words()\n",
    "NLTK_StopWords = set(NLTK_StopWords)\n",
    "Sastrawi_StopWords_id = set(Sastrawi_StopWords_id)\n",
    "Personal_StopWords_en = set(Personal_StopWords_en)\n",
    "Personal_StopWords_id = set(Personal_StopWords_id)\n",
    "\n",
    "T = casefolding\n",
    "T_en = [t for t in word_tokenize(T) if t not in NLTK_StopWords]\n",
    "print(' '.join(T_en))\n",
    "T_id = [t for t in word_tokenize(T) if t not in Sastrawi_StopWords_id]\n",
    "print(' '.join(T_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nah   di app go jek sekarang   kita bisa   kasihlebih juga pake go pay   bentuk apresiasi buat orang yang mageran kaya gue   dibantu kirim2 barang   dan gue bisa terima kasih dalam bentuk nyata     \n"
     ]
    }
   ],
   "source": [
    "# Spacy Lemmatizer menggunakan entitas wordnet (akan dibahas lebih detail di segmen berikutnya)\n",
    "#hapus stopword\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.id import Indonesian\n",
    "nlp_en = spacy.load('en')\n",
    "nlp_id = Indonesian() \n",
    "\n",
    "idn = nlp_id(casefolding)\n",
    "print( ' '.join( k.lemma_ for k in idn ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nah', 'di', 'app', 'go', 'jek', 'sekarang', 'kita', 'bisa', 'kasihlebih', 'juga', 'pake', 'go', 'pay', 'bentuk', 'apresiasi', 'buat', 'orang', 'yang', 'mageran', 'kaya', 'gue', 'dibantu', 'kirim', '2', 'barang', 'dan', 'gue', 'bisa', 'berterima', 'kasih', 'dalam', 'bentuk', 'nyata']\n"
     ]
    }
   ],
   "source": [
    "# tokenisasi = misahin kata per kata\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "Tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "tokenisasi=Tokenizer.tokenize(filtering) # tokenisasi dari hasil filtering di atas\n",
    "print(tokenisasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slang\n",
    "\n",
    "Slangs = TS.LoadDocuments(file = 'C:/WinPython_64bit/notebooks/data/slang.dic')[0]\n",
    "    \n",
    "SlangDict={}\n",
    "for slang in Slangs:\n",
    "    try:\n",
    "        key, value = slang.split(':')\n",
    "        SlangDict[key.strip()]= value.strip()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    " \n",
    "stops, lemmatizer = TS.LoadStopWords(lang='id')\n",
    "for i,d in tqdm(enumerate(Tweets)):\n",
    "    Tweets[i] = TS.cleanText(d, SlangDict, lemma=lemmatizer, stops=None, symbols_remove=True, min_charLen=2)\n",
    "print(Tweets[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hapus stopword, belom tau caranya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweet yang sudah diberi label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### membentuk VSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(677, 10244)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Membentuk VSM\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2, 2)) #ngram itu feature selection\n",
    "vsm = vectorizer.fit_transform(Tweets)\n",
    "vsm = vsm[vsm.getnnz(1)>0][:,vsm.getnnz(0)>0]\n",
    "vsm.shape # bentuk vsm dari kolom 'tweet' csv bersih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1821)\t0.21869641997484815\n",
      "  (0, 7891)\t0.19648885998078694\n",
      "  (0, 446)\t0.16129071015768456\n",
      "  (0, 7)\t0.21869641997484815\n",
      "  (0, 1533)\t0.17855947711269207\n",
      "  (0, 7513)\t0.21869641997484815\n",
      "  (0, 1393)\t0.1834982701517458\n",
      "  (0, 7254)\t0.21869641997484815\n",
      "  (0, 2907)\t0.21869641997484815\n",
      "  (0, 5767)\t0.205705830145807\n",
      "  (0, 10026)\t0.21869641997484815\n",
      "  (0, 5611)\t0.21869641997484815\n",
      "  (0, 476)\t0.17428129998672573\n",
      "  (0, 7677)\t0.21869641997484815\n",
      "  (0, 7798)\t0.17855947711269207\n",
      "  (0, 704)\t0.21869641997484815\n",
      "  (0, 7769)\t0.21869641997484815\n",
      "  (0, 4105)\t0.21869641997484815\n",
      "  (0, 2204)\t0.21869641997484815\n",
      "  (0, 2205)\t0.21869641997484815\n",
      "  (0, 2475)\t0.21869641997484815\n",
      "  (0, 6419)\t0.21869641997484815\n",
      "  (0, 10045)\t0.21869641997484815\n",
      "  (1, 1004)\t1.0\n",
      "  (2, 7512)\t0.2983827579912732\n",
      "  :\t:\n",
      "  (676, 8562)\t0.16532033125332815\n",
      "  (676, 9247)\t0.16532033125332815\n",
      "  (676, 971)\t0.3306406625066563\n",
      "  (676, 8161)\t0.16532033125332815\n",
      "  (676, 2941)\t0.16532033125332815\n",
      "  (676, 9038)\t0.16532033125332815\n",
      "  (676, 236)\t0.16532033125332815\n",
      "  (676, 237)\t0.16532033125332815\n",
      "  (676, 4167)\t0.16532033125332815\n",
      "  (676, 9307)\t0.16532033125332815\n",
      "  (676, 1872)\t0.16532033125332815\n",
      "  (676, 9676)\t0.16532033125332815\n",
      "  (676, 8493)\t0.16532033125332815\n",
      "  (676, 8971)\t0.16532033125332815\n",
      "  (676, 1827)\t0.16532033125332815\n",
      "  (676, 9117)\t0.16532033125332815\n",
      "  (676, 4521)\t0.16532033125332815\n",
      "  (676, 5984)\t0.16532033125332815\n",
      "  (676, 2202)\t0.16532033125332815\n",
      "  (676, 4944)\t0.16532033125332815\n",
      "  (676, 6732)\t0.16532033125332815\n",
      "  (676, 5191)\t0.16532033125332815\n",
      "  (676, 6027)\t0.16532033125332815\n",
      "  (676, 9306)\t0.16532033125332815\n",
      "  (676, 8162)\t0.16532033125332815\n"
     ]
    }
   ],
   "source": [
    "print(vsm) # di baris 0 kolom 1821 nilai katanya (tfidf) 0.21 dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datalabel = pd.read_csv('C:/WinPython_64bit/notebooks/analisis gopay/perbulan/gabungan_bersih _labeled.csv')\n",
    "datalabel.head()\n",
    "label = datalabel['Label']\n",
    "label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(330,)\n",
      "(142,)\n",
      "(330,)\n",
      "(142,)\n"
     ]
    }
   ],
   "source": [
    "# Split data menjadi data train dan test\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X = datalabel.Cleaned_Tweet #dari csv gabungan_bersih yang udah dilabelin aja\n",
    "y = datalabel.Label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.3)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### membentuk model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'plis ovo sm saing sobat missqueen ku nikmat indahnya hidup'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-199-70cfa5b5a9c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmulai\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#melakukan Cross-Validation dengan SVM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mscores_svm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdSVM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# perhatikan sekarang kita menggunakan seluruh data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mwaktu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmulai\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Interval Akurasi 95 CI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython_64bit\\python-3.6.5.amd64\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    343\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython_64bit\\python-3.6.5.amd64\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             return_times=True)\n\u001b[1;32m--> 206\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython_64bit\\python-3.6.5.amd64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython_64bit\\python-3.6.5.amd64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython_64bit\\python-3.6.5.amd64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython_64bit\\python-3.6.5.amd64\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython_64bit\\python-3.6.5.amd64\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython_64bit\\python-3.6.5.amd64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython_64bit\\python-3.6.5.amd64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython_64bit\\python-3.6.5.amd64\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython_64bit\\python-3.6.5.amd64\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython_64bit\\python-3.6.5.amd64\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mc:\\winpython_64bit\\python-3.6.5.amd64\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    431\u001b[0m                                       force_all_finite)\n\u001b[0;32m    432\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'plis ovo sm saing sobat missqueen ku nikmat indahnya hidup'"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "dSVM = svm.SVC(decision_function_shape='ovo') #sudah dicoba 'sigmoid', 'poly' dan 'rbf' dan menghasilkan hal yang tidak jauh berbeda\n",
    "mulai = time.time()\n",
    "#melakukan Cross-Validation dengan SVM\n",
    "scores_svm = cross_val_score(dSVM, X_train, y_train, cv=10,scoring='accuracy') # perhatikan sekarang kita menggunakan seluruh data\n",
    "waktu = time.time() - mulai\n",
    "# Interval Akurasi 95 CI \n",
    "print(\"Accuracy SVM: %0.2f (+/- %0.2f), Waktu = %0.3f detik\" % (scores_svm.mean(), scores_svm.std() * 2, waktu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'nctsmtown 127 regular4th win moment jaeyong taeyong mbak boa \\n\\n ga total pulsa masing2 25k orang menang \\n\\n rt aja'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-169-d68f572267a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fitting and evaluate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdSVM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdSVM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_SVM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdSVM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Akurasi = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_SVM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython_64bit\\python-3.6.5.amd64\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython_64bit\\python-3.6.5.amd64\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mc:\\winpython_64bit\\python-3.6.5.amd64\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    431\u001b[0m                                       force_all_finite)\n\u001b[0;32m    432\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'nctsmtown 127 regular4th win moment jaeyong taeyong mbak boa \\n\\n ga total pulsa masing2 25k orang menang \\n\\n rt aja'"
     ]
    }
   ],
   "source": [
    "# Fitting and evaluate the model\n",
    "dSVM = svm.SVC(C = 10**5)\n",
    "dSVM.fit(X_train, y_train)\n",
    "y_SVM = dSVM.predict(X_test)\n",
    "print('Akurasi = ', accuracy_score(y_test, y_SVM))\n",
    "print(confusion_matrix(y_test, y_SVM))\n",
    "print(classification_report(y_test, y_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'nctsmtown 127 regular4th win moment jaeyong taeyong mbak boa \\n\\n ga total pulsa masing2 25k orang menang \\n\\n rt aja'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-177-5f57e7a9b279>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdSVM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecision_function_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ovo'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#sudah dicoba 'sigmoid', 'poly' dan 'rbf' dan menghasilkan hal yang tidak jauh berbeda\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdSVM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0my_SVM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdSVM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_SVM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython_64bit\\python-3.6.5.amd64\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython_64bit\\python-3.6.5.amd64\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mc:\\winpython_64bit\\python-3.6.5.amd64\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    431\u001b[0m                                       force_all_finite)\n\u001b[0;32m    432\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'nctsmtown 127 regular4th win moment jaeyong taeyong mbak boa \\n\\n ga total pulsa masing2 25k orang menang \\n\\n rt aja'"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "dSVM = svm.SVC(decision_function_shape='ovo') #sudah dicoba 'sigmoid', 'poly' dan 'rbf' dan menghasilkan hal yang tidak jauh berbeda\n",
    "dSVM.fit(X_train,y_train)\n",
    "y_SVM=dSVM.predict(X_test)\n",
    "accuracy_score(y_test,y_SVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
